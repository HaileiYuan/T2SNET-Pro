# -*- coding: utf-8 -*-
"""“Comparise_Baseline_All

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gv5qk9Ux9aLfwpAQ_gy8DSWKOBEzSyaZ
"""

import pandas as pd

url_univclass= 'https://raw.githubusercontent.com/irenekarijadi/RF-LSTM-CEEMDAN/main/Dataset/data%20of%20UnivClass_Abby.csv'
univclass= pd.read_csv(url_univclass)
data_univclass= univclass[(univclass['timestamp'] > '2015-03-01') & (univclass['timestamp'] < '2015-06-01')]
dfs_univclass=data_univclass['energy']
datas_univclass=pd.DataFrame(dfs_univclass)


url_univdorm= 'https://raw.githubusercontent.com/irenekarijadi/RF-LSTM-CEEMDAN/main/Dataset/data%20of%20UnivDorm_Prince.csv'
univdorm= pd.read_csv(url_univdorm)
data_univdorm= univdorm[(univdorm['timestamp'] > '2015-03-01') & (univdorm['timestamp'] < '2015-06-01')]
dfs_univdorm=data_univdorm['energy']
datas_univdorm=pd.DataFrame(dfs_univdorm)


url_univlab= 'https://raw.githubusercontent.com/irenekarijadi/RF-LSTM-CEEMDAN/main/Dataset/data%20of%20UnivLab_Christy.csv'
univlab= pd.read_csv(url_univlab)
data_univlab= univlab[(univlab['timestamp'] > '2015-03-01') & (univlab['timestamp'] < '2015-06-01')]
dfs_univlab=data_univlab['energy']
datas_univlab=pd.DataFrame(dfs_univlab)

url_office= 'https://raw.githubusercontent.com/irenekarijadi/RF-LSTM-CEEMDAN/main/Dataset/data%20of%20Office_Abigail.csv'
office= pd.read_csv(url_office)
data_office= office[(office['timestamp'] > '2015-03-01') & (office['timestamp'] < '2015-06-01')]
dfs_office=data_office['energy']
datas_office=pd.DataFrame(dfs_office)

url_primclass= 'https://raw.githubusercontent.com/irenekarijadi/RF-LSTM-CEEMDAN/main/Dataset/data%20of%20PrimClass_Jaden.csv'
primclass= pd.read_csv(url_primclass)
data_primclass= primclass[(primclass['timestamp'] > '2015-03-01') & (primclass['timestamp'] < '2015-06-01')]
dfs_primclass=data_primclass['energy']
datas_primclass=pd.DataFrame(dfs_primclass)

!pip install dataframe_image
!pip install emd-signal
!pip install tensorflow
!pip install pandas
!pip install dataframe_image
!pip install scikit-learn

import sys
import warnings

if not sys.warnoptions:
    warnings.simplefilter('ignore')

from PyEMD import CEEMDAN
import numpy
import math
import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from sklearn import metrics

import time
import dataframe_image as dfi

max_features=8 # the feature number of each node is set to 8, as it is suggested to be one-third of the feature's number (Lahouar and Slama,2017)
lr=0.001 #learning rate LSTM as recommended in (Kingma and Ba, 2014)
optimizer='Adam' #Adam is used as the optimizer for LSTM as it is computationally efficient (Dubey, Ashutosh Kumar, et al,2021)
neuron=64
epoch=100 #(Jorges et al, 2021)
batch_size=64 #(Kandel et al,2020)
n_hours=24 #in this study, to predict one hour ahead predicton, we use input from the previous 24 hour energy consumption
data_partition=0.8 #in this study, we divided the data into 80% of data as training data and 20% of the data as testing data

hours=n_hours
data_partition=data_partition
max_features=max_features
epoch=epoch
batch_size=batch_size
neuron=neuron
lr=lr
optimizer=optimizer

def create_dataset(dataset, look_back=1):
    dataX, dataY = [], []
    for i in range(len(dataset)-look_back-1):
        a = dataset[i:(i+look_back), 0]
        dataX.append(a)
        dataY.append(dataset[i + look_back, 0])
    return numpy.array(dataX), numpy.array(dataY)

def hybrid_ceemdan_rf(datass,look_back,data_partition,max_features):
  from PyEMD.CEEMDAN import CEEMDAN

  import numpy as np
  import pandas as pd

  dfs=datass
  s = dfs.values

  emd = CEEMDAN(epsilon=0.05)
  emd.noise_seed(12345)

  IMFs = emd(s)


  full_imf=pd.DataFrame(IMFs)
  data_imf=full_imf.T

  import pandas as pd

  pred_test=[]
  test_ori=[]
  pred_train=[]
  train_ori=[]


  for col in data_imf:
      datasetss2=pd.DataFrame(data_imf[col])
      datasets=datasetss2.values
      train_size = int(len(datasets) * data_partition)
      test_size = len(datasets) - train_size
      train, test = datasets[0:train_size], datasets[train_size:len(datasets)]

      trainX, trainY = create_dataset(train, look_back)
      testX, testY = create_dataset(test, look_back)
      X_train=pd.DataFrame(trainX)
      Y_train=pd.DataFrame(trainY)
      X_test=pd.DataFrame(testX)
      Y_test=pd.DataFrame(testY)
      sc_X = StandardScaler()
      sc_y = StandardScaler()
      X= sc_X.fit_transform(X_train)
      y= sc_y.fit_transform(Y_train)
      X1= sc_X.fit_transform(X_test)
      y1= sc_y.fit_transform(Y_test)
      y=y.ravel()
      y1=y1.ravel()

      import numpy

      numpy.random.seed(1234)
      import tensorflow as tf
      tf.random.set_seed(1234)


      from sklearn.ensemble import RandomForestRegressor


      grid = RandomForestRegressor(max_features=max_features)
      grid.fit(X,y)
      y_pred_train= grid.predict(X)
      y_pred_test= grid.predict(X1)

      y_pred_test=pd.DataFrame(y_pred_test)
      y_pred_train=pd.DataFrame(y_pred_train)

      y1=pd.DataFrame(y1)
      y=pd.DataFrame(y)

      y_test= sc_y.inverse_transform (y1)
      y_train= sc_y.inverse_transform (y)

      y_pred_test1= sc_y.inverse_transform (y_pred_test)
      y_pred_train1= sc_y.inverse_transform (y_pred_train)


      pred_test.append(y_pred_test1)
      test_ori.append(y_test)
      pred_train.append(y_pred_train1)
      train_ori.append(y_train)


  result_pred_test= pd.DataFrame.from_records(pred_test)
  result_pred_train= pd.DataFrame.from_records(pred_train)


  a=result_pred_test.sum(axis = 0, skipna = True)
  b=result_pred_train.sum(axis = 0, skipna = True)


  dataframe=pd.DataFrame(dfs)
  dataset=dataframe.values

  train_size = int(len(dataset) * data_partition)
  test_size = len(dataset) - train_size
  train, test = dataset[0:train_size], dataset[train_size:len(dataset)]

  trainX, trainY = create_dataset(train, look_back)
  testX, testY = create_dataset(test, look_back)
  X_train=pd.DataFrame(trainX)
  Y_train=pd.DataFrame(trainY)
  X_test=pd.DataFrame(testX)
  Y_test=pd.DataFrame(testY)

  sc_X = StandardScaler()
  sc_y = StandardScaler()
  X= sc_X.fit_transform(X_train)
  y= sc_y.fit_transform(Y_train)
  X1= sc_X.fit_transform(X_test)
  y1= sc_y.fit_transform(Y_test)
  y=y.ravel()
  y1=y1.ravel()


  trainX = numpy.reshape(X, (X.shape[0], 1, X.shape[1]))
  testX = numpy.reshape(X1, (X1.shape[0], 1, X1.shape[1]))

  numpy.random.seed(1234)
  import tensorflow as tf
  tf.random.set_seed(1234)

  y1=pd.DataFrame(y1)
  y=pd.DataFrame(y)
  y_test= sc_y.inverse_transform (y1)
  y_train= sc_y.inverse_transform (y)

  a= pd.DataFrame(a)
  y_test= pd.DataFrame(y_test)

  #summarize the fit of the model
  mape=mean_absolute_percentage_error(y_test,a)
  rmse= sqrt(mean_squared_error(y_test,a))
  mae=metrics.mean_absolute_error(y_test,a)



  return mape,rmse,mae

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error

from sklearn import metrics
from sklearn.preprocessing import StandardScaler
from math import sqrt

def percentage_error(actual, predicted):
    res = numpy.empty(actual.shape)
    for j in range(actual.shape[0]):
        if actual[j] != 0:
            res[j] = (actual[j] - predicted[j]) / actual[j]
        else:
            res[j] = predicted[j] / np.mean(actual)
    return res

def mean_absolute_percentage_error(y_true, y_pred):
    return numpy.mean(numpy.abs(percentage_error(numpy.asarray(y_true), numpy.asarray(y_pred)))) * 100


def hybrid_ceemdan_lstm(datass,look_back,data_partition,max_features,epoch,batch_size,neuron,lr,optimizer):
    from PyEMD.CEEMDAN import CEEMDAN

    dfs=datass
    s = dfs.values

    emd = CEEMDAN(epsilon=0.05)
    emd.noise_seed(12345)

    IMFs = emd(s)


    full_imf=pd.DataFrame(IMFs)
    data_imf=full_imf.T

    pred_test=[]
    test_ori=[]
    pred_train=[]
    train_ori=[]


    for col in data_imf:

        datasetss2=pd.DataFrame(data_imf[col])
        datasets=datasetss2.values
        train_size = int(len(datasets) * data_partition)
        test_size = len(datasets) - train_size
        train, test = datasets[0:train_size], datasets[train_size:len(datasets)]

        trainX, trainY = create_dataset(train, look_back)
        testX, testY = create_dataset(test, look_back)
        X_train=pd.DataFrame(trainX)
        Y_train=pd.DataFrame(trainY)
        X_test=pd.DataFrame(testX)
        Y_test=pd.DataFrame(testY)
        sc_X = StandardScaler()
        sc_y = StandardScaler()
        X= sc_X.fit_transform(X_train)
        y= sc_y.fit_transform(Y_train)
        X1= sc_X.fit_transform(X_test)
        y1= sc_y.fit_transform(Y_test)
        y=y.ravel()
        y1=y1.ravel()

        import numpy

        trainX = numpy.reshape(X, (X.shape[0], 1, X.shape[1]))
        testX = numpy.reshape(X1, (X1.shape[0], 1, X1.shape[1]))

        numpy.random.seed(1234)
        import tensorflow as tf
        tf.random.set_seed(1234)


        neuron=neuron

        model = tf.keras.Sequential()
        model.add(tf.keras.layers.LSTM(units = neuron,input_shape=(trainX.shape[1], trainX.shape[2])))
        model.add(tf.keras.layers.Dense(1))
        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)
        model.compile(loss='mse',optimizer=optimizer)

        numpy.random.seed(1234)


        # Fitting the RNN to the Training set
        model.fit(trainX, y, epochs = epoch, batch_size = batch_size,verbose=0)

        # make predictions
        y_pred_train = model.predict(trainX)
        y_pred_test = model.predict(testX)

        # make predictions

        y_pred_test= numpy.array(y_pred_test).ravel()
        y_pred_test=pd.DataFrame(y_pred_test)
        y1=pd.DataFrame(y1)
        y=pd.DataFrame(y)
        y_pred_train= numpy.array(y_pred_train).ravel()
        y_pred_train=pd.DataFrame(y_pred_train)


        y_test= sc_y.inverse_transform (y1)
        y_train= sc_y.inverse_transform (y)

        y_pred_test1= sc_y.inverse_transform (y_pred_test)
        y_pred_train1= sc_y.inverse_transform (y_pred_train)


        pred_test.append(y_pred_test1)
        test_ori.append(y_test)
        pred_train.append(y_pred_train1)
        train_ori.append(y_train)


    result_pred_test= pd.DataFrame.from_records(pred_test)
    result_pred_train= pd.DataFrame.from_records(pred_train)


    a=result_pred_test.sum(axis = 0, skipna = True)
    b=result_pred_train.sum(axis = 0, skipna = True)


    dataframe=pd.DataFrame(dfs)
    dataset=dataframe.values

    train_size = int(len(dataset) * data_partition)
    test_size = len(dataset) - train_size
    train, test = dataset[0:train_size], dataset[train_size:len(dataset)]

    trainX, trainY = create_dataset(train, look_back)
    testX, testY = create_dataset(test, look_back)
    X_train=pd.DataFrame(trainX)
    Y_train=pd.DataFrame(trainY)
    X_test=pd.DataFrame(testX)
    Y_test=pd.DataFrame(testY)

    sc_X = StandardScaler()
    sc_y = StandardScaler()
    X= sc_X.fit_transform(X_train)
    y= sc_y.fit_transform(Y_train)
    X1= sc_X.fit_transform(X_test)
    y1= sc_y.fit_transform(Y_test)
    y=y.ravel()
    y1=y1.ravel()


    trainX = numpy.reshape(X, (X.shape[0], 1, X.shape[1]))
    testX = numpy.reshape(X1, (X1.shape[0], 1, X1.shape[1]))

    numpy.random.seed(1234)
    import tensorflow as tf
    tf.random.set_seed(1234)

    y1=pd.DataFrame(y1)
    y=pd.DataFrame(y)

    y_test= sc_y.inverse_transform (y1)
    y_train= sc_y.inverse_transform (y)


    a= pd.DataFrame(a)
    y_test= pd.DataFrame(y_test)



   #summarize the fit of the model
    mape=mean_absolute_percentage_error(y_test,a)
    rmse= sqrt(mean_squared_error(y_test,a))
    mae=metrics.mean_absolute_error(y_test,a)

    return mape,rmse,mae



def proposed_method(datass,look_back,data_partition,max_features,epoch,batch_size,neuron,lr,optimizer):
    from PyEMD.CEEMDAN import CEEMDAN
    dfs=datass
    s = dfs.values
    emd = CEEMDAN(epsilon=0.05)
    emd.noise_seed(12345)
    IMFs = emd(s)
    full_imf=pd.DataFrame(IMFs)
    data_imf=full_imf.T
    pred_test=[]
    n_imf=len(data_imf.columns)
    k=list(range(1,n_imf))
    m=[0]

    for i in m:

        datasetss2=pd.DataFrame(data_imf[i])
        datasets=datasetss2.values
        train_size = int(len(datasets) * data_partition)
        train, test = datasets[0:train_size], datasets[train_size:len(datasets)]

        trainX, trainY = create_dataset(train, look_back)
        testX, testY = create_dataset(test, look_back)
        X_train=pd.DataFrame(trainX)
        Y_train=pd.DataFrame(trainY)
        X_test=pd.DataFrame(testX)
        sc_X = StandardScaler()
        sc_y = StandardScaler()
        X= sc_X.fit_transform(X_train)
        y= sc_y.fit_transform(Y_train)
        X1= sc_X.fit_transform(X_test)
        y=y.ravel()

        import numpy
        numpy.random.seed(1234)
        from sklearn.ensemble import RandomForestRegressor

        grid = RandomForestRegressor(max_features=max_features)
        grid.fit(X,y)
        y_pred_test= grid.predict(X1)
        y_pred_test=pd.DataFrame(y_pred_test)
        y_pred_test1= sc_y.inverse_transform (y_pred_test)
        pred_test.append(y_pred_test1)

    for i in k:
        datasetss2=pd.DataFrame(data_imf[i])
        datasets=datasetss2.values
        train_size = int(len(datasets) * data_partition)
        train, test = datasets[0:train_size], datasets[train_size:len(datasets)]
        trainX, trainY = create_dataset(train, look_back)
        testX, testY = create_dataset(test, look_back)
        X_train=pd.DataFrame(trainX)
        Y_train=pd.DataFrame(trainY)
        X_test=pd.DataFrame(testX)
        Y_test=pd.DataFrame(testY)
        sc_X = StandardScaler()
        sc_y = StandardScaler()
        X= sc_X.fit_transform(X_train)
        y= sc_y.fit_transform(Y_train)
        X1= sc_X.fit_transform(X_test)
        y1= sc_y.fit_transform(Y_test)
        y=y.ravel()

        trainX = numpy.reshape(X, (X.shape[0], 1, X.shape[1]))
        testX = numpy.reshape(X1, (X1.shape[0], 1, X1.shape[1]))

        numpy.random.seed(1234)
        import tensorflow as tf
        tf.random.set_seed(1234)
        model = tf.keras.Sequential()
        model.add(tf.keras.layers.LSTM(units = neuron,input_shape=(trainX.shape[1], trainX.shape[2])))
        model.add(tf.keras.layers.Dense(1))
        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)
        model.compile(loss='mse',optimizer=optimizer)

     # Fitting the RNN to the Training set
        model.fit(trainX, y, epochs = epoch, batch_size = batch_size,verbose=0)
        # make predictions
        y_pred_test = model.predict(testX)
        # make predictions
        y_pred_test= numpy.array(y_pred_test).ravel()
        y_pred_test=pd.DataFrame(y_pred_test)
        y_pred_test1= sc_y.inverse_transform(y_pred_test)
        pred_test.append(y_pred_test1)

    result_pred_test= pd.DataFrame.from_records(pred_test)
    print(result_pred_test.shape)
    a=result_pred_test.sum(axis = 0, skipna = True)

    dataframe=pd.DataFrame(dfs)
    dataset=dataframe.values
    train_size = int(len(dataset) * data_partition)
    train, test = dataset[0:train_size], dataset[train_size:len(dataset)]
    testX, testY = create_dataset(test, look_back)
    Y_test=pd.DataFrame(testY)
    a= pd.DataFrame(a)
    y_test= pd.DataFrame(Y_test)

   #summarize the fit of the model
    print(y_test.shape, a.shape)
    mape=mean_absolute_percentage_error(y_test,a)
    rmse= sqrt(mean_squared_error(y_test,a))
    mae=metrics.mean_absolute_error(y_test,a)

    return mape,rmse,mae,a,y_test

def lr_model(datass,look_back,data_partition):

    datasets=datass.values
    train_size = int(len(datasets) * data_partition)
    test_size = len(datasets) - train_size
    train, test = datasets[0:train_size], datasets[train_size:len(datasets)]

    trainX, trainY = create_dataset(train, look_back)
    testX, testY = create_dataset(test, look_back)
    X_train=pd.DataFrame(trainX)
    Y_train=pd.DataFrame(trainY)
    X_test=pd.DataFrame(testX)
    Y_test=pd.DataFrame(testY)
    sc_X = StandardScaler()
    sc_y = StandardScaler()

    X= sc_X.fit_transform(X_train)
    y= sc_y.fit_transform(Y_train)
    X1= sc_X.fit_transform(X_test)
    y1= sc_y.fit_transform(Y_test)
    y=y.ravel()
    y1=y1.ravel()
    import tensorflow as tf

    numpy.random.seed(1234)
    tf.random.set_seed(1234)

    from sklearn.linear_model import LinearRegression

    grid = LinearRegression()

    grid.fit(X,y)
    y_pred_train_lr= grid.predict(X)
    y_pred_test_lr= grid.predict(X1)

    y_pred_train_lr=pd.DataFrame(y_pred_train_lr)
    y_pred_test_lr=pd.DataFrame(y_pred_test_lr)

    y1=pd.DataFrame(y1)
    y=pd.DataFrame(y)


    y_pred_test1_lr= sc_y.inverse_transform (y_pred_test_lr)
    y_pred_train1_lr=sc_y.inverse_transform (y_pred_train_lr)

    y_test= sc_y.inverse_transform (y1)
    y_train= sc_y.inverse_transform (y)

    y_pred_test1_rf=pd.DataFrame(y_pred_test1_lr)
    y_pred_train1_rf=pd.DataFrame(y_pred_train1_lr)

    y_test= pd.DataFrame(y_test)


    #summarize the fit of the model
    mape=mean_absolute_percentage_error(y_test,y_pred_test1_lr)
    rmse= sqrt(mean_squared_error(y_test,y_pred_test1_lr))
    mae=metrics.mean_absolute_error(y_test,y_pred_test1_lr)


    return mape,rmse,mae

def svr_model(datass,look_back,data_partition):

    datasets=datass.values
    train_size = int(len(datasets) * data_partition)
    test_size = len(datasets) - train_size
    train, test = datasets[0:train_size], datasets[train_size:len(datasets)]

    trainX, trainY = create_dataset(train, look_back)
    testX, testY = create_dataset(test, look_back)
    X_train=pd.DataFrame(trainX)
    Y_train=pd.DataFrame(trainY)
    X_test=pd.DataFrame(testX)
    Y_test=pd.DataFrame(testY)
    sc_X = StandardScaler()
    sc_y = StandardScaler()

    X= sc_X.fit_transform(X_train)
    y= sc_y.fit_transform(Y_train)
    X1= sc_X.fit_transform(X_test)
    y1= sc_y.fit_transform(Y_test)
    y=y.ravel()
    y1=y1.ravel()

    numpy.random.seed(1234)

    import tensorflow as tf
    tf.random.set_seed(1234)


    from sklearn.svm import SVR

    grid = SVR()
    grid.fit(X,y)
    y_pred_train_svr= grid.predict(X)
    y_pred_test_svr= grid.predict(X1)

    y_pred_train_svr=pd.DataFrame(y_pred_train_svr)
    y_pred_test_svr=pd.DataFrame(y_pred_test_svr)

    y1=pd.DataFrame(y1)
    y=pd.DataFrame(y)


    y_pred_test1_svr= sc_y.inverse_transform (y_pred_test_svr)
    y_pred_train1_svr=sc_y.inverse_transform (y_pred_train_svr)

    y_test= sc_y.inverse_transform (y1)
    y_train= sc_y.inverse_transform (y)

    y_pred_test1_svr=pd.DataFrame(y_pred_test1_svr)
    y_pred_train1_svr=pd.DataFrame(y_pred_train1_svr)

    y_test= pd.DataFrame(y_test)


    #summarize the fit of the model
    mape=mean_absolute_percentage_error(y_test,y_pred_test1_svr)
    rmse= sqrt(mean_squared_error(y_test,y_pred_test1_svr))
    mae=metrics.mean_absolute_error(y_test,y_pred_test1_svr)


    return mape,rmse,mae

def ann_model(datass,look_back,data_partition):


    datasets=datass.values
    train_size = int(len(datasets) * data_partition)
    test_size = len(datasets) - train_size
    train, test = datasets[0:train_size], datasets[train_size:len(datasets)]
    trainX, trainY = create_dataset(train, look_back)
    testX, testY = create_dataset(test, look_back)
    X_train=pd.DataFrame(trainX)
    Y_train=pd.DataFrame(trainY)
    X_test=pd.DataFrame(testX)
    Y_test=pd.DataFrame(testY)
    sc_X = StandardScaler()
    sc_y = StandardScaler()

    X= sc_X.fit_transform(X_train)
    y= sc_y.fit_transform(Y_train)
    X1= sc_X.fit_transform(X_test)
    y1= sc_y.fit_transform(Y_test)
    y=y.ravel()
    y1=y1.ravel()

    import numpy

    trainX = numpy.reshape(X, (X.shape[0], 1, X.shape[1]))
    testX = numpy.reshape(X1, (X1.shape[0], 1, X1.shape[1]))


    numpy.random.seed(1234)
    import tensorflow as tf
    tf.random.set_seed(1234)


    from sklearn.neural_network import MLPRegressor

    model= MLPRegressor(random_state=1,activation='tanh').fit(X,y)

    numpy.random.seed(1234)


    # make predictions
    y_pred_train = model.predict(X)
    y_pred_test = model.predict(X1)
    y_pred_test= numpy.array(y_pred_test).ravel()

    y_pred_test=pd.DataFrame(y_pred_test)
    y1=pd.DataFrame(y1)

    y_pred_test1= sc_y.inverse_transform (y_pred_test)
    y_test= sc_y.inverse_transform (y1)







    #summarize the fit of the model
    mape=mean_absolute_percentage_error(y_test,y_pred_test1)
    rmse= sqrt(mean_squared_error(y_test,y_pred_test1))
    mae=metrics.mean_absolute_error(y_test,y_pred_test1)


    return mape,rmse,mae

def rf_model(datass,look_back,data_partition,max_features):

    datasets=datass.values
    train_size = int(len(datasets) * data_partition)
    test_size = len(datasets) - train_size
    train, test = datasets[0:train_size], datasets[train_size:len(datasets)]

    trainX, trainY = create_dataset(train, look_back)
    testX, testY = create_dataset(test, look_back)
    X_train=pd.DataFrame(trainX)
    Y_train=pd.DataFrame(trainY)
    X_test=pd.DataFrame(testX)
    Y_test=pd.DataFrame(testY)
    sc_X = StandardScaler()
    sc_y = StandardScaler()

    X= sc_X.fit_transform(X_train)
    y= sc_y.fit_transform(Y_train)
    X1= sc_X.fit_transform(X_test)
    y1= sc_y.fit_transform(Y_test)
    y=y.ravel()
    y1=y1.ravel()

    numpy.random.seed(1234)
    import tensorflow as tf
    tf.random.set_seed(1234)

    from sklearn.ensemble import RandomForestRegressor

    grid = RandomForestRegressor(max_features=max_features)
    grid.fit(X,y)
    y_pred_train_rf= grid.predict(X)
    y_pred_test_rf= grid.predict(X1)

    y_pred_train_rf=pd.DataFrame(y_pred_train_rf)
    y_pred_test_rf=pd.DataFrame(y_pred_test_rf)

    y1=pd.DataFrame(y1)
    y=pd.DataFrame(y)


    y_pred_test1_rf= sc_y.inverse_transform (y_pred_test_rf)
    y_pred_train1_rf=sc_y.inverse_transform (y_pred_train_rf)

    y_test= sc_y.inverse_transform (y1)
    y_train= sc_y.inverse_transform (y)

    y_pred_test1_rf=pd.DataFrame(y_pred_test1_rf)
    y_pred_train1_rf=pd.DataFrame(y_pred_train1_rf)

    y_test= pd.DataFrame(y_test)


    #summarize the fit of the model
    mape=mean_absolute_percentage_error(y_test,y_pred_test1_rf)
    rmse= sqrt(mean_squared_error(y_test,y_pred_test1_rf))
    mae=metrics.mean_absolute_error(y_test,y_pred_test1_rf)


    return mape,rmse,mae

def lstm_model(datass,look_back,data_partition,max_features,epoch,batch_size,neuron,lr,optimizer):
    datasets=datass.values
    train_size = int(len(datasets) * data_partition)
    test_size = len(datasets) - train_size
    train, test = datasets[0:train_size], datasets[train_size:len(datasets)]
    trainX, trainY = create_dataset(train, look_back)
    testX, testY = create_dataset(test, look_back)
    X_train=pd.DataFrame(trainX)
    Y_train=pd.DataFrame(trainY)
    X_test=pd.DataFrame(testX)
    Y_test=pd.DataFrame(testY)
    sc_X = StandardScaler()
    sc_y = StandardScaler()

    X= sc_X.fit_transform(X_train)
    y= sc_y.fit_transform(Y_train)
    X1= sc_X.fit_transform(X_test)
    y1= sc_y.fit_transform(Y_test)
    y=y.ravel()
    y1=y1.ravel()
    trainX1 = numpy.reshape(X, (X.shape[0],1,X.shape[1]))
    testX1 = numpy.reshape(X1, (X1.shape[0],1,X1.shape[1]))

    numpy.random.seed(1234)
    import tensorflow as tf
    tf.random.set_seed(1234)

    import os
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'


    neuron=neuron
    model = tf.keras.Sequential()
    model.add(tf.keras.layers.LSTM(units = neuron,input_shape=(trainX1.shape[1], trainX1.shape[2])))
    model.add(tf.keras.layers.Dense(1))
    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)
    model.compile(loss='mse',optimizer=optimizer)
#    model.summary()


  # Fitting the RNN to the Training s
    model.fit(trainX1, y, epochs = epoch, batch_size = batch_size,verbose=0)
  # make predictions
    y_pred_train = model.predict(trainX1)
    y_pred_test = model.predict(testX1)
    y_pred_test= numpy.array(y_pred_test).ravel()

    y_pred_test=pd.DataFrame(y_pred_test)
    y_pred_test1= sc_y.inverse_transform (y_pred_test)
    y1=pd.DataFrame(y1)

    y_test= sc_y.inverse_transform (y1)

    from sklearn.metrics import mean_squared_error
    from sklearn.metrics import mean_absolute_error

    from sklearn import metrics

    mape=mean_absolute_percentage_error(y_test,y_pred_test1)
    rmse= sqrt(mean_squared_error(y_test,y_pred_test1))
    mae=metrics.mean_absolute_error(y_test,y_pred_test1)
    return mape,rmse,mae

import numpy as np
def tcn_model(datass,look_back,data_partition,max_features,epoch,batch_size,neuron,lr,optimizer):
    datasets=datass.values
    train_size = int(len(datasets) * data_partition)
    test_size = len(datasets) - train_size
    train, test = datasets[0:train_size], datasets[train_size:len(datasets)]
    trainX, trainY = create_dataset(train, look_back)
    testX, testY = create_dataset(test, look_back)
    X_train=pd.DataFrame(trainX)
    Y_train=pd.DataFrame(trainY)
    X_test=pd.DataFrame(testX)
    Y_test=pd.DataFrame(testY)
    sc_X = StandardScaler()
    sc_y = StandardScaler()

    X= sc_X.fit_transform(X_train)
    y= sc_y.fit_transform(Y_train)
    X1= sc_X.fit_transform(X_test)
    y1= sc_y.fit_transform(Y_test)
    y=y.ravel()
    y1=y1.ravel()
    trainX1 = numpy.reshape(X, (X.shape[0],1,X.shape[1]))
    testX1 = numpy.reshape(X1, (X1.shape[0],1,X1.shape[1]))

    numpy.random.seed(1234)
    import tensorflow as tf
    tf.random.set_seed(1234)

    import os
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'


    neuron=neuron
    print(trainX1.shape, y.shape)

    # Keras实现类似TCN
    model = tf.keras.Sequential()

    # # 使用卷积层模拟TCN，使用膨胀卷积（Dilated Convolutions）
    # model.add(tf.keras.layers.Conv1D(filters=neuron, kernel_size=3, dilation_rate=1, activation='relu', input_shape=(trainX1.shape[1], trainX1.shape[2])))
    # model.add(tf.keras.layers.Conv1D(filters=neuron, kernel_size=3, dilation_rate=2, activation='relu'))
    # model.add(tf.keras.layers.Conv1D(filters=neuron, kernel_size=3, dilation_rate=4, activation='relu'))
    # model.add(tf.keras.layers.Flatten())  # 展平层，通常卷积层后加上
    # model.add(tf.keras.layers.Dense(1))  # 输出层，预测一个连续值

    model.add(tf.keras.layers.Conv1D(filters=neuron, kernel_size=1, dilation_rate=1, activation='relu', input_shape=(trainX1.shape[1], trainX1.shape[2])))
    model.add(tf.keras.layers.Conv1D(filters=neuron, kernel_size=1, dilation_rate=2, activation='relu'))
    model.add(tf.keras.layers.Conv1D(filters=neuron, kernel_size=1, dilation_rate=4, activation='relu'))
    model.add(tf.keras.layers.Flatten())  # 展平层，通常卷积层后加上
    model.add(tf.keras.layers.Dense(1))  # 输出层，预测一个连续值


    # 编译模型
    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)
    model.compile(loss='mse', optimizer=optimizer)



    # 训练模型
    model.fit(trainX1, y, epochs=epoch, batch_size=batch_size, verbose=0)

    # 预测训练集和测试集
    y_pred_train = model.predict(trainX1)
    y_pred_test = model.predict(testX1)

    # 逆标准化
    y_pred_test = np.array(y_pred_test).ravel()
    y_pred_test = pd.DataFrame(y_pred_test)
    y_pred_test1 = sc_y.inverse_transform(y_pred_test)
    y1 = pd.DataFrame(y1)
    y_test = sc_y.inverse_transform(y1)

    # 评估模型
    mape = mean_absolute_percentage_error(y_test, y_pred_test1)
    rmse = sqrt(mean_squared_error(y_test, y_pred_test1))
    mae = metrics.mean_absolute_error(y_test, y_pred_test1)

    return mape, rmse, mae

from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error
from sklearn import metrics
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from math import sqrt

def knn_model(datass, look_back, data_partition):
    datasets = datass.values
    train_size = int(len(datasets) * data_partition)
    test_size = len(datasets) - train_size
    train, test = datasets[0:train_size], datasets[train_size:len(datasets)]

    trainX, trainY = create_dataset(train, look_back)
    testX, testY = create_dataset(test, look_back)
    X_train = pd.DataFrame(trainX)
    Y_train = pd.DataFrame(trainY)
    X_test = pd.DataFrame(testX)
    Y_test = pd.DataFrame(testY)

    sc_X = StandardScaler()
    sc_y = StandardScaler()

    X = sc_X.fit_transform(X_train)
    y = sc_y.fit_transform(Y_train)
    X1 = sc_X.transform(X_test)
    y1 = sc_y.transform(Y_test)
    y = y.ravel()
    y1 = y1.ravel()

    # KNN Regressor Model
    knn = KNeighborsRegressor(n_neighbors=5)  # You can change n_neighbors based on hyperparameter tuning
    knn.fit(X, y)

    # Predictions
    y_pred_train_knn = knn.predict(X)
    y_pred_test_knn = knn.predict(X1)

    # Inverse transform
    y_pred_train_knn = sc_y.inverse_transform(pd.DataFrame(y_pred_train_knn))
    y_pred_test_knn = sc_y.inverse_transform(pd.DataFrame(y_pred_test_knn))
    y_test = sc_y.inverse_transform(pd.DataFrame(y1))
    y_train = sc_y.inverse_transform(pd.DataFrame(y))

    # Calculate performance metrics
    mape = mean_absolute_percentage_error(y_test, y_pred_test_knn)
    rmse = sqrt(mean_squared_error(y_test, y_pred_test_knn))
    mae = metrics.mean_absolute_error(y_test, y_pred_test_knn)

    return mape, rmse, mae

from sklearn.linear_model import Ridge
from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error

def ridge_model(datass, look_back, data_partition):
    datasets = datass.values
    train_size = int(len(datasets) * data_partition)
    test_size = len(datasets) - train_size
    train, test = datasets[0:train_size], datasets[train_size:len(datasets)]

    trainX, trainY = create_dataset(train, look_back)
    testX, testY = create_dataset(test, look_back)
    X_train = pd.DataFrame(trainX)
    Y_train = pd.DataFrame(trainY)
    X_test = pd.DataFrame(testX)
    Y_test = pd.DataFrame(testY)

    sc_X = StandardScaler()
    sc_y = StandardScaler()

    X = sc_X.fit_transform(X_train)
    y = sc_y.fit_transform(Y_train)
    X1 = sc_X.transform(X_test)
    y1 = sc_y.transform(Y_test)
    y = y.ravel()
    y1 = y1.ravel()

    # Ridge Regressor Model
    ridge = Ridge(alpha=1.0)
    ridge.fit(X, y)

    # Predictions
    y_pred_train_ridge = ridge.predict(X)
    y_pred_test_ridge = ridge.predict(X1)

    # Inverse transform
    y_pred_train_ridge = sc_y.inverse_transform(pd.DataFrame(y_pred_train_ridge))
    y_pred_test_ridge = sc_y.inverse_transform(pd.DataFrame(y_pred_test_ridge))
    y_test = sc_y.inverse_transform(pd.DataFrame(y1))
    y_train = sc_y.inverse_transform(pd.DataFrame(y))

    # Calculate performance metrics
    mape = mean_absolute_percentage_error(y_test, y_pred_test_ridge)
    rmse = sqrt(mean_squared_error(y_test, y_pred_test_ridge))
    mae = metrics.mean_absolute_error(y_test, y_pred_test_ridge)

    return mape, rmse, mae

!pip install statsmodels

# from statsmodels.tsa.holtwinters import ExponentialSmoothing
# from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error

# from statsmodels.tsa.holtwinters import ExponentialSmoothing
# from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error
# from sklearn import metrics
# import pandas as pd
# import numpy as np
# from sklearn.preprocessing import StandardScaler
# from math import sqrt
# import time

# def ha_model(datass, look_back, data_partition):
#     datasets = datass.values
#     train_size = int(len(datasets) * data_partition)
#     test_size = len(datasets) - train_size
#     train, test = datasets[0:train_size], datasets[train_size:len(datasets)]

#     # 生成数据集
#     trainX, trainY = create_dataset(train, look_back)
#     testX, testY = create_dataset(test, look_back)

#     # 确保 trainX 和 trainY，testX 和 testY 长度一致
#     if len(trainX) != len(trainY):
#         raise ValueError(f"trainX length: {len(trainX)}, trainY length: {len(trainY)} are not the same.")
#     if len(testX) != len(testY):
#         raise ValueError(f"testX length: {len(testX)}, testY length: {len(testY)} are not the same.")

#     # 转换为DataFrame
#     X_train = pd.DataFrame(trainX)
#     Y_train = pd.DataFrame(trainY)
#     X_test = pd.DataFrame(testX)
#     Y_test = pd.DataFrame(testY)

#     # 标准化数据
#     sc_X = StandardScaler()
#     sc_y = StandardScaler()
#     X = sc_X.fit_transform(X_train)
#     y = sc_y.fit_transform(Y_train)
#     X1 = sc_X.transform(X_test)
#     y1 = sc_y.transform(Y_test)
#     y = y.ravel()  # 转换为一维数组
#     y1 = y1.ravel()  # 转换为一维数组

#     # 使用Holt-Winters（HA）方法进行建模
#     model = ExponentialSmoothing(y, trend='add', seasonal='add', seasonal_periods=24)  # 假设周期为24小时
#     fit_model = model.fit()

#     # 进行预测
#     y_pred_train_ha = fit_model.fittedvalues
#     y_pred_test_ha = fit_model.forecast(len(test))  # 对测试集进行预测

#     # 逆标准化预测结果
#     y_pred_train_ha = sc_y.inverse_transform(pd.DataFrame(y_pred_train_ha))
#     y_pred_test_ha = sc_y.inverse_transform(pd.DataFrame(y_pred_test_ha))

#     # 逆标准化实际值
#     y_test = sc_y.inverse_transform(pd.DataFrame(y1))
#     y_train = sc_y.inverse_transform(pd.DataFrame(y))

#     # 评估模型性能
#     mape = mean_absolute_percentage_error(y_test, y_pred_test_ha)
#     rmse = sqrt(mean_squared_error(y_test, y_pred_test_ha))
#     mae = metrics.mean_absolute_error(y_test, y_pred_test_ha)

#     return mape, rmse, mae

# # 使用时间计算代码执行时间
# start_time = time.time()
# ha_model_univdorm = ha_model(datas_univdorm, hours, data_partition)
# ha_model_time_univdorm = time.time() - start_time
# print("--- %s seconds - HA MODEL Regression - univdorm ---" % (ha_model_time_univdorm))

datas_univdorm = datas_univclass
dfs_univdorm = dfs_univclass

# ridge_model 岭回归
start_time = time.time()
ridge_model_univdorm=ridge_model(datas_univdorm,hours,data_partition)
ridge_model_time_univdorm=time.time() - start_time
print("--- %s seconds - RIDGE MODEL Regression- univdorm ---" % (ridge_model_time_univdorm))


# knn model

start_time = time.time()
knn_univdorm=knn_model(datas_univdorm,hours,data_partition)
knn_time_univdorm=time.time() - start_time
print("--- %s seconds - KNN Regression MODEL- univdorm ---" % (knn_time_univdorm))

#Linear Regression

start_time = time.time()
lr_univdorm=lr_model(datas_univdorm,hours,data_partition)
lr_time_univdorm=time.time() - start_time
print("--- %s seconds - Linear Regression- univdorm ---" % (lr_time_univdorm))

#Support Vector Regression
start_time = time.time()
svr_univdorm=svr_model(datas_univdorm,hours,data_partition)
svr_time_univdorm=time.time() - start_time
print("--- %s seconds - Support Vector Regression- univdorm ---" % (svr_time_univdorm))


#ANN
start_time = time.time()
ann_univdorm=ann_model(datas_univdorm,hours,data_partition)
ann_time_univdorm=time.time() - start_time
print("--- %s seconds - ANN- univdorm ---" % (ann_time_univdorm))

#random forest
start_time = time.time()
rf_univdorm=rf_model(datas_univdorm,hours,data_partition,max_features)
rf_time_univdorm=time.time() - start_time
print("--- %s seconds - Random Forest- univdorm ---" % (rf_time_univdorm))

#LSTM
start_time = time.time()
lstm_univdorm=lstm_model(datas_univdorm,hours,data_partition,max_features,epoch,batch_size,neuron,lr,optimizer)
lstm_time_univdorm=time.time() - start_time
print("--- %s seconds - lstm- univdorm ---" % (lstm_time_univdorm))


#CEEMDAN RF
start_time = time.time()
ceemdan_rf_univdorm=hybrid_ceemdan_rf(dfs_univdorm,hours,data_partition,max_features)
ceemdan_rf_time_univdorm=time.time() - start_time
print("--- %s seconds - ceemdan_rf- univdorm ---" % (ceemdan_rf_time_univdorm))

#CEEMDAN LSTM
start_time = time.time()
ceemdan_lstm_univdorm=hybrid_ceemdan_lstm(dfs_univdorm,hours,data_partition,max_features,epoch,batch_size,neuron,lr,optimizer)
ceemdan_lstm_time_univdorm=time.time() - start_time
print("--- %s seconds - ceemdan_lstm- univdorm ---" % (ceemdan_lstm_time_univdorm))

#proposed method
start_time = time.time()
proposed_method_univdorm=proposed_method(dfs_univdorm,hours,data_partition,max_features,epoch,batch_size,neuron,lr,optimizer)
proposed_method_time_univdorm=time.time() - start_time
print("--- %s seconds - proposed_method- univdorm ---" % (proposed_method_time_univdorm))


# tcn method
start_time = time.time()
tcn_model_univdorm = tcn_model(datas_univdorm,hours,data_partition,max_features,epoch,batch_size,neuron,lr,optimizer)
tcn_model_time_univdorm=time.time() - start_time
print("--- %s seconds - tcn_model- univdorm ---" % (tcn_model_time_univdorm))

running_time_univdorm=pd.DataFrame([lr_time_univdorm,svr_time_univdorm,ann_time_univdorm,
                                   rf_time_univdorm,lstm_time_univdorm,ceemdan_rf_time_univdorm,
                                   ceemdan_lstm_time_univdorm,proposed_method_time_univdorm, tcn_model_time_univdorm, knn_time_univdorm, ridge_model_time_univdorm])
running_time_univdorm=running_time_univdorm.T
running_time_univdorm.columns=['LR','SVR','ANN','RF','LSTM','CEEMDAN RF','CEEMDAN LSTM','Proposed Method', 'TCN', 'KNN', 'Ridge']
proposed_method_univdorm_df=proposed_method_univdorm[0:3]
result_univdorm=pd.DataFrame([lr_univdorm,svr_univdorm,ann_univdorm,rf_univdorm,lstm_univdorm,ceemdan_rf_univdorm,
                    ceemdan_lstm_univdorm,proposed_method_univdorm_df,tcn_model_univdorm,knn_univdorm, ridge_model_univdorm])
result_univdorm=result_univdorm.T
result_univdorm.columns=['LR','SVR','ANN','RF','LSTM','CEEMDAN RF','CEEMDAN LSTM','Proposed Method', 'TCN', 'KNN', 'Ridge']
univdorm_summary=pd.concat([result_univdorm,running_time_univdorm],axis=0)

# univdorm_summary.set_axis(['MAPE(%)', 'RMSE','MAE','running time (s)'], axis='index')
univdorm_summary.index = ['MAPE(%)', 'RMSE', 'MAE', 'running time (s)']

univdorm_summary.style.set_caption("University Dormitory Results")
index = univdorm_summary.index
index.name = "university dormitory results"
univdorm_summary

def tcn_model(datass,look_back,data_partition,max_features,epoch,batch_size,neuron,lr,optimizer):
    datasets=datass.values
    train_size = int(len(datasets) * data_partition)
    test_size = len(datasets) - train_size
    train, test = datasets[0:train_size], datasets[train_size:len(datasets)]
    trainX, trainY = create_dataset(train, look_back)
    testX, testY = create_dataset(test, look_back)
    X_train=pd.DataFrame(trainX)
    Y_train=pd.DataFrame(trainY)
    X_test=pd.DataFrame(testX)
    Y_test=pd.DataFrame(testY)
    sc_X = StandardScaler()
    sc_y = StandardScaler()

    X= sc_X.fit_transform(X_train)
    y= sc_y.fit_transform(Y_train)
    X1= sc_X.fit_transform(X_test)
    y1= sc_y.fit_transform(Y_test)
    y=y.ravel()
    y1=y1.ravel()
    trainX1 = numpy.reshape(X, (X.shape[0],1,X.shape[1]))
    testX1 = numpy.reshape(X1, (X1.shape[0],1,X1.shape[1]))

    numpy.random.seed(1234)
    import tensorflow as tf
    tf.random.set_seed(1234)

    import os
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'


    neuron=neuron

    # Keras实现类似TCN
    model = tf.keras.Sequential()

    # 使用卷积层模拟TCN，使用膨胀卷积（Dilated Convolutions）
    model.add(layers.Conv1D(filters=neuron, kernel_size=3, dilation_rate=1, activation='relu', input_shape=(trainX1.shape[1], trainX1.shape[2])))
    model.add(layers.Conv1D(filters=neuron, kernel_size=3, dilation_rate=2, activation='relu'))
    model.add(layers.Conv1D(filters=neuron, kernel_size=3, dilation_rate=4, activation='relu'))
    model.add(layers.Flatten())  # 展平层，通常卷积层后加上
    model.add(layers.Dense(1))  # 输出层，预测一个连续值

    # 编译模型
    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)
    model.compile(loss='mse', optimizer=optimizer)

    # 训练模型
    model.fit(trainX1, y, epochs=epoch, batch_size=batch_size, verbose=0)

    # 预测训练集和测试集
    y_pred_train = model.predict(trainX1)
    y_pred_test = model.predict(testX1)

    # 逆标准化
    y_pred_test = np.array(y_pred_test).ravel()
    y_pred_test = pd.DataFrame(y_pred_test)
    y_pred_test1 = sc_y.inverse_transform(y_pred_test)
    y1 = pd.DataFrame(y1)
    y_test = sc_y.inverse_transform(y1)

    # 评估模型
    mape = mean_absolute_percentage_error(y_test, y_pred_test1)
    rmse = sqrt(mean_squared_error(y_test, y_pred_test1))
    mae = metrics.mean_absolute_error(y_test, y_pred_test1)

    return mape, rmse, mae

print(dfs_univdorm.values.shape)

import time
import pandas as pd
import numpy as np
from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error
from math import sqrt

# ======================== 封装运行模型的函数 ========================
def run_models_for_dataset(dataset, dataset_name,
                           look_back=hours,
                           data_partition=data_partition,
                           max_features=max_features,
                           epoch=epoch,
                           batch_size=batch_size,
                           neuron=neuron,
                           lr=lr,
                           optimizer=optimizer):
    """
    参数说明：
    dataset: 要处理的数据集（DataFrame格式）
    dataset_name: 数据集名称（用于输出标识）
    look_back: 时间窗口大小，默认为24
    data_partition: 数据分割比例，默认为0.8
    max_features: 随机森林的最大特征数，默认为8
    epoch: LSTM训练轮数，默认为100
    batch_size: 批大小，默认为64
    neuron: LSTM神经元数量，默认为64
    lr: 学习率，默认为0.001
    optimizer: 优化器，默认为Adam
    """

    # 定义所有模型及其运行函数
    models = {
        'LR': lr_model,
        'SVR': svr_model,
        'ANN': ann_model,
        'RF': rf_model,
        'LSTM': lstm_model,
        'CEEMDAN_RF': hybrid_ceemdan_rf,
        'CEEMDAN_LSTM': hybrid_ceemdan_lstm,
        'Proposed_Method': proposed_method,
        'TCN': tcn_model,
        'KNN': knn_model,
        'Ridge': ridge_model
    }

    results = []
    times = []

    print(f"\n====== 正在处理数据集：{dataset_name} ======")

    # 循环运行每个模型
    for model_name, model_func in models.items():
        start_time = time.time()
        try:
            # 处理需要不同参数的模型
            if model_name in ['CEEMDAN_RF', 'CEEMDAN_LSTM', 'Proposed_Method']:
                if model_name == 'CEEMDAN_RF':
                    datasets_ceemdan_rf = dataset['energy']
                    mape, rmse, mae = model_func(datasets_ceemdan_rf, look_back, data_partition, max_features)
                elif model_name == 'CEEMDAN_LSTM':
                    datasets_ceemdan_lstm = dataset['energy']
                    mape, rmse, mae = model_func(datasets_ceemdan_lstm, look_back, data_partition, max_features,
                                               epoch, batch_size, neuron, lr, optimizer)
                elif model_name == 'Proposed_Method':
                    proposed_method_dataset = dataset['energy']
                    mape, rmse, mae, *_ = model_func(proposed_method_dataset, look_back, data_partition, max_features,
                                                    epoch, batch_size, neuron, lr, optimizer)
            elif model_name in ['LSTM', 'TCN']:
                mape, rmse, mae = model_func(dataset, look_back, data_partition, max_features,
                                            epoch, batch_size, neuron, lr, optimizer)
            elif model_name == 'RF':
                mape, rmse, mae = model_func(dataset, look_back, data_partition, max_features)
            else:
                mape, rmse, mae = model_func(dataset, look_back, data_partition)

            run_time = time.time() - start_time
            print(f"{model_name}完成 | MAPE: {mape:.2f}% | 耗时: {run_time:.1f}s")

            results.append((mape, rmse, mae))
            times.append(run_time)

        except Exception as e:
            print(f"在{model_name}模型运行过程中出现错误：{str(e)}")
            results.append((np.nan, np.nan, np.nan))
            times.append(np.nan)

    # 转换为DataFrame
    result_df = pd.DataFrame(results,
                            columns=['MAPE(%)', 'RMSE', 'MAE'],
                            index=models.keys())

    time_df = pd.DataFrame(times,
                          columns=['Running Time(s)'],
                          index=models.keys())

    # 合并结果
    final_df = pd.concat([result_df, time_df], axis=1)
    final_df.insert(0, 'Dataset', dataset_name)

    return final_df

# ======================== 准备所有数据集 ========================
datasets = {
    'UnivClass': datas_univclass,
    'UnivDorm': datas_univdorm,
    'UnivLab': datas_univlab,
    'Office': datas_office,
    'PrimClass': datas_primclass
}

# ======================== 运行所有数据集 ========================
all_results = []

for name, data in datasets.items():
    try:
        df = run_models_for_dataset(data, name)
        all_results.append(df)
    except Exception as e:
        print(f"处理数据集{name}时发生严重错误：{str(e)}")
        continue

# ======================== 合并并保存结果 ========================
final_results = pd.concat(all_results)

# 打印完整结果
print("\n====== 最终结果汇总 ======")
print(final_results)

# 保存为CSV
final_results.to_csv("All_Datasets_Results.csv")